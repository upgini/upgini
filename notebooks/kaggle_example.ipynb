{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Example: Store Item Demand Forecasting Challenge\n",
    "\n",
    "Following this example notebook you'll see how easy you can boost your ML tasks with Upgini. We will enrich a dataset with relevant features and build a better model upon them.\n",
    "\n",
    "If you haven't got our library yet, you can install it now. Also, you can install CatBoost for the last part of this demonstartion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq upgini catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the input data\n",
    "\n",
    "For this demo we will use the train dataset from [Store Item Demand Forecasting Challenge](https://www.kaggle.com/c/demand-forecasting-kernels-only). You can download it from [here](https://www.kaggle.com/c/demand-forecasting-kernels-only/data?select=train.csv) or get from [our repo](https://github.com/upgini/upgini/raw/main/notebooks/train.csv.zip).\n",
    "\n",
    "To speed up the search let's take a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335813</th>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630838</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365685</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322781</th>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151590</th>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store  item  sales\n",
       "335813 2017-07-14      4    19     56\n",
       "630838 2015-05-19      6    35     45\n",
       "365685 2014-05-01      1    21     48\n",
       "322781 2016-11-06      7    18     85\n",
       "151590 2013-02-02      4     9     46"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import exists\n",
    "import pandas as pd\n",
    "\n",
    "df_path = \"train.csv.zip\" if exists(\"train.csv.zip\") else \"https://github.com/upgini/upgini/raw/main/notebooks/train.csv.zip\"\n",
    "df = pd.read_csv(df_path)\n",
    "df = df.sample(n=7_000, random_state=0)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 5 years of records from 2013 to 2017. Let's split it into the train (2013â€“2016) and the evaluation (2017) parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df[\"date\"] < \"2017-01-01\"]\n",
    "test = df[df[\"date\"] >= \"2017-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also separate features from targets for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.drop(columns=[\"sales\"])\n",
    "train_target = train[\"sales\"]\n",
    "test_features = test.drop(columns=[\"sales\"])\n",
    "test_target = test[\"sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search relevant features with FeaturesEnricher\n",
    "\n",
    "Next, we will use FeaturesEnricher on the train dataset to find features best suited for this particular target prediction. To do this we need to specify the column containing dates and provide the target to predict. Also, we can specify any number of additional datasets to evaluate the features. We will use our test dataset to get the eavaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_1b1a2_row0_col1,#T_1b1a2_row1_col1{\n",
       "            background-color:  #DAF7A6;\n",
       "        }</style><table id=\"T_1b1a2_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Key</th>        <th class=\"col_heading level0 col1\" >Status</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1b1a2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_1b1a2_row0_col0\" class=\"data row0 col0\" >date</td>\n",
       "                        <td id=\"T_1b1a2_row0_col1\" class=\"data row0 col1\" >All valid</td>\n",
       "                        <td id=\"T_1b1a2_row0_col2\" class=\"data row0 col2\" >All values in this column are good to go</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1b1a2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_1b1a2_row1_col0\" class=\"data row1 col0\" >target</td>\n",
       "                        <td id=\"T_1b1a2_row1_col1\" class=\"data row1 col1\" >All valid</td>\n",
       "                        <td id=\"T_1b1a2_row1_col2\" class=\"data row1 col2\" >All values in this column are good to go</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14487f3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running f7fd28ca-ae0a-4335-abbc-4108a957d6d5 search request.\n",
      "We'll email you once it's completed. Please wait a few minutes.\n",
      "/\n",
      "\u001b[92m\u001b[1m\n",
      "Quality metrics\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match rate</th>\n",
       "      <th>rmse</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.488501</td>\n",
       "      <td>5.477250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval 1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>13.620399</td>\n",
       "      <td>5.202253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        match rate       rmse    uplift\n",
       "train        100.0  10.488501  5.477250\n",
       "eval 1       100.0  13.620399  5.202253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Following features was used for accuracy uplift estimation: store, item\n"
     ]
    }
   ],
   "source": [
    "from upgini import FeaturesEnricher, SearchKey\n",
    "\n",
    "enricher = FeaturesEnricher(\n",
    "    search_keys={\"date\": SearchKey.DATE},\n",
    "    keep_input=True,\n",
    ")\n",
    "enricher.fit(train_features, train_target, eval_set=[(test_features, test_target)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case the task is auto-detected as a regression. Hence the metric to optimize is auto-selected as RMSE.\n",
    "\n",
    "In the output you see RMSE values for the train dataset (using cross-validation) and for every evaluation dataset we have provided. There are also match rate values (a percent share of rows enriched with features) and uplift values (a relative improvement in RMSE for the enriched dataset over the initial dataset).\n",
    "\n",
    "Here we can see a strong uplift both on the cross-validation and on the out-of-time validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features and test them locally\n",
    "\n",
    "Finally, we can enrich our datasets with the features found and use them in our own ML pipelines. Lets's enrich both the train and the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_cebba_row0_col1{\n",
       "            background-color:  #DAF7A6;\n",
       "        }</style><table id=\"T_cebba_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Key</th>        <th class=\"col_heading level0 col1\" >Status</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cebba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_cebba_row0_col0\" class=\"data row0 col0\" >date</td>\n",
       "                        <td id=\"T_cebba_row0_col1\" class=\"data row0 col1\" >All valid</td>\n",
       "                        <td id=\"T_cebba_row0_col2\" class=\"data row0 col2\" >All values in this column are good to go</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14fb741d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running d4820c74-21e2-4ce6-bc78-b3809b55179f search request.\n",
      "We'll email you once it's completed. Please wait a few minutes.\n",
      "/\n",
      "Executing transform step...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6ac88_row0_col1{\n",
       "            background-color:  #DAF7A6;\n",
       "        }</style><table id=\"T_6ac88_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Key</th>        <th class=\"col_heading level0 col1\" >Status</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6ac88_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_6ac88_row0_col0\" class=\"data row0 col0\" >date</td>\n",
       "                        <td id=\"T_6ac88_row0_col1\" class=\"data row0 col1\" >All valid</td>\n",
       "                        <td id=\"T_6ac88_row0_col2\" class=\"data row0 col2\" >All values in this column are good to go</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f9595d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running be396cf8-e41b-43f4-88cb-15173ddfe054 search request.\n",
      "We'll email you once it's completed. Please wait a few minutes.\n",
      "/\n",
      "Executing transform step...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>f_b2a0ab34eba8a027</th>\n",
       "      <th>f_aa56f3d319a74c78</th>\n",
       "      <th>f_ef51816499755030</th>\n",
       "      <th>f_6d3bb2c253012f04</th>\n",
       "      <th>f_3337640c6521dd13</th>\n",
       "      <th>f_60091eb7636849ce</th>\n",
       "      <th>f_dcc56f96529a93a4</th>\n",
       "      <th>...</th>\n",
       "      <th>f_4a1d42a953f35713</th>\n",
       "      <th>f_497dd3e95bca8ed1</th>\n",
       "      <th>f_25e8d342b2bdfd7e</th>\n",
       "      <th>f_ef819c0cc6941e1c</th>\n",
       "      <th>f_483435d688c2ba47</th>\n",
       "      <th>f_15f177b331e0a943</th>\n",
       "      <th>f_c934ce6d892f4739</th>\n",
       "      <th>f_2a5a3453dda1e638</th>\n",
       "      <th>f_cb04ccb306995c33</th>\n",
       "      <th>f_1d868ee9e3a2c974</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630838</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.319779</td>\n",
       "      <td>0.570318</td>\n",
       "      <td>0.030312</td>\n",
       "      <td>19</td>\n",
       "      <td>0.395049</td>\n",
       "      <td>5</td>\n",
       "      <td>0.378082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059475</td>\n",
       "      <td>1.170510</td>\n",
       "      <td>0.88291</td>\n",
       "      <td>1.003429</td>\n",
       "      <td>1.076434</td>\n",
       "      <td>1.207199</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.008182</td>\n",
       "      <td>0.879191</td>\n",
       "      <td>1.023048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365685</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.369156</td>\n",
       "      <td>0.536414</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>1</td>\n",
       "      <td>0.331484</td>\n",
       "      <td>5</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>0.968942</td>\n",
       "      <td>0.72102</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.960941</td>\n",
       "      <td>0.950444</td>\n",
       "      <td>1.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322781</th>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.572214</td>\n",
       "      <td>0.178637</td>\n",
       "      <td>0.028914</td>\n",
       "      <td>6</td>\n",
       "      <td>0.251106</td>\n",
       "      <td>11</td>\n",
       "      <td>0.846995</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009348</td>\n",
       "      <td>0.995140</td>\n",
       "      <td>0.90070</td>\n",
       "      <td>0.996151</td>\n",
       "      <td>1.003539</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>22.51</td>\n",
       "      <td>1.090073</td>\n",
       "      <td>1.250052</td>\n",
       "      <td>1.403671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151590</th>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444276</td>\n",
       "      <td>0.180064</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>2</td>\n",
       "      <td>0.265788</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985821</td>\n",
       "      <td>1.005008</td>\n",
       "      <td>0.73470</td>\n",
       "      <td>0.992474</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.972042</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.783288</td>\n",
       "      <td>0.727013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572011</th>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.439849</td>\n",
       "      <td>0.337163</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>19</td>\n",
       "      <td>0.343071</td>\n",
       "      <td>4</td>\n",
       "      <td>0.295890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982740</td>\n",
       "      <td>0.968060</td>\n",
       "      <td>0.72400</td>\n",
       "      <td>1.001320</td>\n",
       "      <td>0.971869</td>\n",
       "      <td>0.946664</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.907873</td>\n",
       "      <td>1.013456</td>\n",
       "      <td>0.986780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store  item  f_b2a0ab34eba8a027  f_aa56f3d319a74c78  \\\n",
       "630838 2015-05-19      6    35            0.319779            0.570318   \n",
       "365685 2014-05-01      1    21            0.369156            0.536414   \n",
       "322781 2016-11-06      7    18            0.572214            0.178637   \n",
       "151590 2013-02-02      4     9            0.444276            0.180064   \n",
       "572011 2014-04-19      4    32            0.439849            0.337163   \n",
       "\n",
       "        f_ef51816499755030  f_6d3bb2c253012f04  f_3337640c6521dd13  \\\n",
       "630838            0.030312                  19            0.395049   \n",
       "365685            0.030364                   1            0.331484   \n",
       "322781            0.028914                   6            0.251106   \n",
       "151590            0.029806                   2            0.265788   \n",
       "572011            0.028215                  19            0.343071   \n",
       "\n",
       "        f_60091eb7636849ce  f_dcc56f96529a93a4  ...  f_4a1d42a953f35713  \\\n",
       "630838                   5            0.378082  ...            1.059475   \n",
       "365685                   5            0.328767  ...            0.982994   \n",
       "322781                  11            0.846995  ...            1.009348   \n",
       "151590                   2            0.087671  ...            0.985821   \n",
       "572011                   4            0.295890  ...            0.982740   \n",
       "\n",
       "        f_497dd3e95bca8ed1  f_25e8d342b2bdfd7e  f_ef819c0cc6941e1c  \\\n",
       "630838            1.170510             0.88291            1.003429   \n",
       "365685            0.968942             0.72102            0.997813   \n",
       "322781            0.995140             0.90070            0.996151   \n",
       "151590            1.005008             0.73470            0.992474   \n",
       "572011            0.968060             0.72400            1.001320   \n",
       "\n",
       "        f_483435d688c2ba47  f_15f177b331e0a943  f_c934ce6d892f4739  \\\n",
       "630838            1.076434            1.207199               12.85   \n",
       "365685            0.973129            0.942934               13.25   \n",
       "322781            1.003539            0.989861               22.51   \n",
       "151590            0.953622            0.972042               12.90   \n",
       "572011            0.971869            0.946664               13.36   \n",
       "\n",
       "        f_2a5a3453dda1e638  f_cb04ccb306995c33  f_1d868ee9e3a2c974  \n",
       "630838            1.008182            0.879191            1.023048  \n",
       "365685            0.960941            0.950444            1.003639  \n",
       "322781            1.090073            1.250052            1.403671  \n",
       "151590            0.958904            0.783288            0.727013  \n",
       "572011            0.907873            1.013456            0.986780  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_train_features = enricher.transform(train_features)\n",
    "enriched_test_features = enricher.transform(test_features)\n",
    "enriched_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've got several dozens of extra features in addition to our initial columns. They should improve the quality of our model.\n",
    "\n",
    "First, we will fit a CatBoost model on the initial train dataset and evaluate the SMAPE metric on the corresponding test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.52217301530647]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoost\n",
    "from catboost.utils import eval_metric\n",
    "\n",
    "model = CatBoost({\"cat_features\": [\"store\", \"item\"], \"verbose\": False, \"allow_writing_files\": False})\n",
    "model.fit(train_features, train_target)\n",
    "preds = model.predict(test_features)\n",
    "eval_metric(test_target.values, preds, \"SMAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit the same model on the enriched train dataset and evaluate the SMAPE metric on the corresponding test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.305751461690585]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_model = CatBoost({\"cat_features\": [\"store\", \"item\"], \"verbose\": False, \"allow_writing_files\": False})\n",
    "enriched_model.fit(enriched_train_features, train_target)\n",
    "enriched_preds = enriched_model.predict(enriched_test_features)\n",
    "eval_metric(test_target.values, enriched_preds, \"SMAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see a much better result after the enrichment. That's the magic of using our library."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84d3963f7282eecda7b76a14a104c509e6daebf9e3eef3217fda5c175b1d27a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
